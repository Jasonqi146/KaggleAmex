{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2771,"status":"ok","timestamp":1657585566315,"user":{"displayName":"Jason Qi","userId":"14258838799704967372"},"user_tz":240},"id":"APTVuy9YzJV3","outputId":"61a3e530-e86f-48c3-ee08-cc4e5d946e90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":338,"status":"ok","timestamp":1657585575117,"user":{"displayName":"Jason Qi","userId":"14258838799704967372"},"user_tz":240},"id":"9LcEK6OIzP33","outputId":"ae789897-6a54-4c73-dc7e-a0da248f5ccb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Kaggle Competition/amex\n"]}],"source":["%cd /content/gdrive/MyDrive/Kaggle\\ Competition/amex"]},{"cell_type":"code","source":["# ! git clone --recursive https://github.com/Microsoft/LightGBM"],"metadata":{"id":"Y-oDNPmDw5_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"],"metadata":{"id":"XAdL3jyJw7Tw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y lightgbm\n","!apt-get install -y libboost-all-dev\n","!git clone --recursive https://github.com/Microsoft/LightGBM"],"metadata":{"id":"TOAIKQrO1ClT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","cd LightGBM\n","# rm -r build\n","mkdir build\n","cd build\n","cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n","make -j$(nproc)"],"metadata":{"id":"3wYbNX5d1FCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cd LightGBM/python-package/;python setup.py install --precompile"],"metadata":{"id":"qdIfGcIY1G00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n","!rm -r LightGBM"],"metadata":{"id":"ShIgz7oK1HOQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDAyvhrazTh1"},"outputs":[],"source":["import os\n","import gc\n","import warnings\n","warnings.filterwarnings('ignore')\n","import random\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import itertools\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import lightgbm as lgb\n","from itertools import combinations"]},{"cell_type":"code","source":["model = joblib.load('Jason_models/LGBM/lgbm_fold4_seed42.pkl')"],"metadata":{"id":"zCh87S8eytKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_evaluate(train, test):\n","    # Label encode categorical features\n","    cat_features = [\n","        \"B_30\",\n","        \"B_38\",\n","        \"D_114\",\n","        \"D_116\",\n","        \"D_117\",\n","        \"D_120\",\n","        \"D_126\",\n","        \"D_63\",\n","        \"D_64\",\n","        \"D_66\",\n","        \"D_68\"\n","    ]\n","    cat_features = [f\"{cf}_last\" for cf in cat_features]\n","    for cat_col in cat_features:\n","        encoder = LabelEncoder()\n","        train[cat_col] = encoder.fit_transform(train[cat_col])\n","        test[cat_col] = encoder.transform(test[cat_col])\n","    # Round last float features to 2 decimal place\n","    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n","    num_cols = [col for col in num_cols if 'last' in col]\n","    for col in num_cols:\n","        train[col + '_round2'] = train[col].round(2)\n","        test[col + '_round2'] = test[col].round(2)\n","    # Get feature list\n","    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n","    params = {\n","        'device': 'gpu',\n","        'objective': 'binary',\n","        'metric': \"binary_logloss\",\n","        'boosting': 'dart',\n","        'seed': CFG.seed,\n","        'num_leaves': 100,\n","        'learning_rate': 0.01,\n","        'feature_fraction': 0.20,\n","        'bagging_freq': 10,\n","        'bagging_fraction': 0.50,\n","        'n_jobs': -1,\n","        'lambda_l2': 2,\n","        'min_data_in_leaf': 40,\n","        'early_stopping_rounds': 100,\n","        'verbosity': -1\n","        }\n","    # Create a numpy array to store test predictions\n","    test_predictions = np.zeros(len(test))\n","    # Create a numpy array to store out of folds predictions\n","    oof_predictions = np.zeros(len(train))\n","    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n","    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n","        print(' ')\n","        print('-'*50)\n","        print(f'Training fold {fold} with {len(features)} features...')\n","        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n","        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n","        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n","        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n","        # model = lgb.train(\n","        #     params = params,\n","        #     train_set = lgb_train,\n","        #     num_boost_round = 10500,\n","        #     valid_sets = [lgb_train, lgb_valid],\n","        #     feval = lgb_amex_metric\n","        #     )\n","        # # Save best model\n","        # %ls\n","        model = joblib.load(('Jason_models/LGBM/lgbm_fold{}_seed{}.pkl').format(fold, CFG.seed))\n","        # Predict validation\n","        val_pred = model.predict(x_val)\n","        # Add to out of folds array\n","        oof_predictions[val_ind] = val_pred\n","        # Predict the test set\n","        test_pred = model.predict(test[features])\n","        test_predictions += test_pred / CFG.n_folds\n","        # Compute fold metric\n","        score = amex_metric(y_val, val_pred)\n","        print(f'Our fold {fold} CV score is {score}')\n","        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n","        gc.collect()\n","    # # Compute out of folds metric\n","    # score = amex_metric(train[CFG.target], oof_predictions)\n","    # print(f'Our out of folds CV score is {score}')\n","    # # Create a dataframe to store out of folds predictions\n","    # %ls\n","    # oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n","    # oof_df.to_csv(('Jason_models/LGBM/OOF/oof_lgbm_baseline_{}fold_seed{}.csv').format(CFG.n_folds, CFG.seed), index = False)\n","    # # Create a dataframe to store test prediction\n","    # test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n","    # %ls\n","    # test_df.to_csv(('Jason_models/LGBM/Predictions/test_lgbm_baseline_{}fold_seed{}.csv').format(CFG.n_folds, CFG.seed), index = False)\n","    \n","# seed_everything(CFG.seed)\n","# train, test = read_data()\n","# train_and_evaluate(train, test)"],"metadata":{"id":"yjqMzm0T0GlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train, test = read_data()\n","train_and_evaluate(train, test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"W5HTCZFy01ML","executionInfo":{"status":"error","timestamp":1657586611502,"user_tz":240,"elapsed":564547,"user":{"displayName":"Jason Qi","userId":"14258838799704967372"}},"outputId":"6131db8c-7d24-4c0d-d1af-e4cb8844b4e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" \n","--------------------------------------------------\n","Training fold 0 with 1011 features...\n","Our fold 0 CV score is 0.8013404122885583\n"," \n","--------------------------------------------------\n","Training fold 1 with 1011 features...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-afe2ad88eafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-7a2deec69522>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Jason_models/LGBM/lgbm_fold{}_seed{}.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Predict validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Add to out of folds array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0moof_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   3609\u001b[0m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[1;32m   3610\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3611\u001b[0;31m                                  data_has_header, validate_features)\n\u001b[0m\u001b[1;32m   3612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m     def refit(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    914\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RR9Psjs71Og"},"outputs":[],"source":["class CFG:\n","    input_dir = 'data/'\n","    output_dir = '/content/gdrive/MyDrive/Kaggle\\ Competition/amex/Jason_model/LGBM/'\n","    seed = 42\n","    n_folds = 5\n","    target = 'target'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l50NBdo-7glE"},"outputs":[],"source":["def read_preprocess_data():\n","    train = pd.read_parquet('data/train.parquet')\n","    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n","    cat_features = [\n","        \"B_30\",\n","        \"B_38\",\n","        \"D_114\",\n","        \"D_116\",\n","        \"D_117\",\n","        \"D_120\",\n","        \"D_126\",\n","        \"D_63\",\n","        \"D_64\",\n","        \"D_66\",\n","        \"D_68\",\n","    ]\n","    num_features = [col for col in features if col not in cat_features]\n","    print('Starting training feature engineer...')\n","    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n","    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n","    train_num_agg.reset_index(inplace = True)\n","    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n","    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n","    train_cat_agg.reset_index(inplace = True)\n","    train_labels = pd.read_csv('data/train_labels.csv')\n","    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n","    del train_num_agg, train_cat_agg\n","    gc.collect()\n","    test = pd.read_parquet('data/test.parquet')\n","    print('Starting test feature engineer...')\n","    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n","    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n","    test_num_agg.reset_index(inplace = True)\n","    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n","    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n","    test_cat_agg.reset_index(inplace = True)\n","    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n","    del test_num_agg, test_cat_agg\n","    gc.collect()\n","    # Save files to disk\n","    train.to_parquet(CFG.input_dir + 'train_fe.parquet')\n","    test.to_parquet(CFG.input_dir + 'test_fe.parquet')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3srWNIUb8QnF"},"outputs":[],"source":["# read_preprocess_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pBxlZZUzdof"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WcktQMV60TLr"},"outputs":[],"source":["def read_data():\n","    train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n","    test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n","    return train, test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pw4YUCN0UqS"},"outputs":[],"source":["def amex_metric(y_true, y_pred):\n","    labels = np.transpose(np.array([y_true, y_pred]))\n","    labels = labels[labels[:, 1].argsort()[::-1]]\n","    weights = np.where(labels[:,0]==0, 20, 1)\n","    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n","    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n","    gini = [0,0]\n","    for i in [1,0]:\n","        labels = np.transpose(np.array([y_true, y_pred]))\n","        labels = labels[labels[:, i].argsort()[::-1]]\n","        weight = np.where(labels[:,0]==0, 20, 1)\n","        weight_random = np.cumsum(weight / np.sum(weight))\n","        total_pos = np.sum(labels[:, 0] *  weight)\n","        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n","        lorentz = cum_pos_found / total_pos\n","        gini[i] = np.sum((lorentz - weight_random) * weight)\n","    return 0.5 * (gini[1]/gini[0] + top_four)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66N6lQhH0XT8"},"outputs":[],"source":["def lgb_amex_metric(y_pred, y_true):\n","    y_true = y_true.get_label()\n","    return 'amex_metric', amex_metric(y_true, y_pred), True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxQlag_-4JV6"},"outputs":[],"source":["def train_and_evaluate(train, test):\n","    # Label encode categorical features\n","    cat_features = [\n","        \"B_30\",\n","        \"B_38\",\n","        \"D_114\",\n","        \"D_116\",\n","        \"D_117\",\n","        \"D_120\",\n","        \"D_126\",\n","        \"D_63\",\n","        \"D_64\",\n","        \"D_66\",\n","        \"D_68\"\n","    ]\n","    cat_features = [f\"{cf}_last\" for cf in cat_features]\n","    for cat_col in cat_features:\n","        encoder = LabelEncoder()\n","        train[cat_col] = encoder.fit_transform(train[cat_col])\n","        test[cat_col] = encoder.transform(test[cat_col])\n","    # Round last float features to 2 decimal place\n","    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n","    num_cols = [col for col in num_cols if 'last' in col]\n","    for col in num_cols:\n","        train[col + '_round2'] = train[col].round(2)\n","        test[col + '_round2'] = test[col].round(2)\n","    # Get feature list\n","    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n","    params = {\n","        'device': 'gpu',\n","        'objective': 'binary',\n","        'metric': \"binary_logloss\",\n","        'boosting': 'dart',\n","        'seed': CFG.seed,\n","        'num_leaves': 100,\n","        'learning_rate': 0.01,\n","        'feature_fraction': 0.20,\n","        'bagging_freq': 10,\n","        'bagging_fraction': 0.50,\n","        'n_jobs': -1,\n","        'lambda_l2': 2,\n","        'min_data_in_leaf': 40,\n","        'early_stopping_rounds': 100,\n","        'verbosity': -1\n","        }\n","    # Create a numpy array to store test predictions\n","    test_predictions = np.zeros(len(test))\n","    # Create a numpy array to store out of folds predictions\n","    oof_predictions = np.zeros(len(train))\n","    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n","    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n","        print(' ')\n","        print('-'*50)\n","        print(f'Training fold {fold} with {len(features)} features...')\n","        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n","        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n","        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n","        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n","        model = lgb.train(\n","            params = params,\n","            train_set = lgb_train,\n","            num_boost_round = 10500,\n","            valid_sets = [lgb_train, lgb_valid],\n","            feval = lgb_amex_metric\n","            )\n","        # Save best model\n","        %ls\n","        joblib.dump(model, ('Jason_models/LGBM/lgbm_fold{}_seed{}.pkl').format(fold, CFG.seed))\n","        # Predict validation\n","        val_pred = model.predict(x_val)\n","        # Add to out of folds array\n","        oof_predictions[val_ind] = val_pred\n","        # Predict the test set\n","        test_pred = model.predict(test[features])\n","        test_predictions += test_pred / CFG.n_folds\n","        # Compute fold metric\n","        score = amex_metric(y_val, val_pred)\n","        print(f'Our fold {fold} CV score is {score}')\n","        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n","        gc.collect()\n","    # Compute out of folds metric\n","    score = amex_metric(train[CFG.target], oof_predictions)\n","    print(f'Our out of folds CV score is {score}')\n","    # Create a dataframe to store out of folds predictions\n","    %ls\n","    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n","    oof_df.to_csv(('Jason_models/LGBM/OOF/oof_lgbm_baseline_{}fold_seed{}.csv').format(CFG.n_folds, CFG.seed), index = False)\n","    # Create a dataframe to store test prediction\n","    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n","    %ls\n","    test_df.to_csv(('Jason_models/LGBM/Predictions/test_lgbm_baseline_{}fold_seed{}.csv').format(CFG.n_folds, CFG.seed), index = False)\n","    \n","# seed_everything(CFG.seed)\n","# train, test = read_data()\n","# train_and_evaluate(train, test)"]},{"cell_type":"code","source":["# oof_df = pd.DataFrame([1,1],[2,1])"],"metadata":{"id":"hgGzEElhOonG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4JOStjL-js3"},"outputs":[],"source":["train, test = read_data()\n","train_and_evaluate(train, test)"]},{"cell_type":"code","source":["%cd "],"metadata":{"id":"aIwdDtsRAiQz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657289463670,"user_tz":240,"elapsed":6,"user":{"displayName":"Jason Qi","userId":"14258838799704967372"}},"outputId":"4935fc63-5f70-40df-dcf7-84ed53168733"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/root\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"LGBM_train.ipynb","provenance":[],"collapsed_sections":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}